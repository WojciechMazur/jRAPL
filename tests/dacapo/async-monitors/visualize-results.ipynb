{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDir = '/home/alejandro/jRAPL/tests/dacapo/async-monitors/jolteon-results-subset'\n",
    "os.chdir(targetDir)\n",
    "files = sorted([ f for f in os.listdir() if f.endswith('.stats.json') ])\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for fname in files:\n",
    "    with open(fname) as f:\n",
    "        parts = fname.split('.')[0].split('_')\n",
    "        benchmark = parts[0]; iteration = int(parts[1]); montype = parts[2]\n",
    "        \n",
    "        d = json.loads(f.read())['metadata']\n",
    "        d['benchmark'] = benchmark; d['iter'] = iteration; d['type'] = montype\n",
    "        data.append(d)\n",
    "    \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}\n",
    "for d in data:\n",
    "    bench = d['benchmark']\n",
    "    del d['benchmark']\n",
    "    if not bench in x.keys(): x[bench] = [d]\n",
    "    else: x[bench].append(d)\n",
    "data = x\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#benchmarks = list(set([ f.split('_')[0] for f in files]))\n",
    "#benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for benchmark in data:\n",
    "    for t in ['java','c-linklist','c-dynamicarray']:\n",
    "        av_samples = statistics.mean( [ d['numSamples'] for d in data[benchmark] if d['type'] == t] )\n",
    "        av_lifetime = statistics.mean( [ d['lifetime'] for d in data[benchmark] if d['type'] == t] )\n",
    "        \n",
    "        if not benchmark in res.keys(): res[benchmark] = dict()\n",
    "        if not t in res[benchmark].keys(): res[benchmark][t] = dict()\n",
    "        \n",
    "        res[benchmark][t]['avg_samples'] = av_samples\n",
    "        res[benchmark][t]['avg_lifetime'] = av_lifetime\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "java = []\n",
    "c_da = []\n",
    "c_ll = []\n",
    "bar_width = 0.25\n",
    "for d in data:\n",
    "    labels.append(d)\n",
    "    d_ = data[d]\n",
    "    java.append(d_['java']['avg_samples'])\n",
    "    c_ll.append(d_['c-linklist']['avg_samples'])\n",
    "    c_da.append(d_['c-dynamicarray']['avg_samples'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 600\n",
    "r1 = np.arange(len(c_ll))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "plt.barh(r1, c_da, bar_width, color='#003f5c', edgecolor=\"white\", label='C Dynamic Array')\n",
    "plt.barh(r2, c_ll, bar_width, color='#bc5090', edgecolor=\"white\", label='C Linked List')\n",
    "plt.barh(r3, java, bar_width, color='#ffa600', edgecolor=\"white\", label='Java')\n",
    "\n",
    "plt.ylabel('benchmark', fontweight='bold')\n",
    "plt.xlabel('Number of samples', fontweight='bold')\n",
    "plt.yticks([r + bar_width for r in range(len(c_ll))], labels)\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,25)\n",
    "#plt.show()\n",
    "\n",
    "#003f5c\n",
    "#bc5090\n",
    "#ffa600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating two suplots per benchmark for [lifetime, nSamples]\n",
    "'''\n",
    "for bench in res:\n",
    "    data = res[bench]\n",
    "    #fig = plt.figure()\n",
    "    fig, (axs) = plt.subplots(1,2 ,figsize=(10,5) )\n",
    "    fig.suptitle('avg num samples and avg lifetime')\n",
    "    \n",
    "    ax = axs.flat[0]\n",
    "    montypes = list(data.keys())\n",
    "    num_samples_list = [ data[t]['avg_samples'] for t in data ]\n",
    "    title = bench+\"_average_samples\"\n",
    "    ax.set_title(title)\n",
    "    ax.bar(montypes,num_samples_list)\n",
    "    \n",
    "    ax = axs.flat[1]\n",
    "    montypes = list(data.keys())\n",
    "    lifetime_list = [ data[t]['avg_lifetime'] for t in data ]\n",
    "    ax.bar(montypes,lifetime_list)\n",
    "    ax.set_title(bench+\"_avg lifetime\")\n",
    "\n",
    "    plt.savefig(bench+\"_numsamples\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}