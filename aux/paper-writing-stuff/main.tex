\documentclass{article}
\usepackage[margin=0.75in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[section]{placeins}
\usepackage{graphicx}
\graphicspath{{./images/}}
\usepackage{float}
\usepackage{listings}
\usepackage{framed}
\usepackage{color}

\newcommand{\dnote}[1]{{\bf\it \textcolor{blue}{David: #1}}}
\newcommand{\anote}[1]{{\bf\it \textcolor{magenta}{Alejandro: #1}}}
\newcommand{\ourframework}[0]{{jRAPL }}
\newcommand{\todo}[1]{{\bf \tt \textcolor{red}{todo: #1}}}
\newcommand{\todoflag}[0]{{\bf \tt \textcolor{red}{todo}}}

\title{jRAPL}
\author{Alejandro Servetto}
\begin{document}
\maketitle

\anote{Just to be clear, while I put some thought into how my wording sounds, I haven't usually gone back and done a full revision of my writing, so if any of it sounds bad or awkward it's because it's a draft, not because I'm bad at writing ;)}

\input{intro}
\input{background}
\input{methodology}
\input{msr}
\input{results}

\section{Proposed other experiments}
    I wanted to suggest these as possible experiments / software improvements. Let me know what you think.

    \subsection{Better C side sleeping}
        \textbf{Not precise to microseconds.} Precise at ms, but, sleeping for 1ms doesn't actually take 1000us. Around 1100 or so on average. This is bad if repeatedly taking samples, as the extra time adds up and you get less samples than you expect, if you're sleeping for single digit ms times. You'd expect 1000 samples per second if sleeping at 1ms, but you don't get that many.
        
        There are more precise timers in C that I could try to implement, Timur showed me a thing that I could see if it works here.
        
    \subsection{Shrinking the size of the data brought across the JNI}
        I've noticed that the size of the string I bring across the JNI has a significant impact on JNI overhead; on Jolteon, samples take longer because I'm returning data for 2 sockets, so the string is longer.
        
        I could experiment with serializing the data in a binary format instead of a human readable format, and then parsing it on the Java side. Something like a byte array, or a string where each character is a byte of the C-side energy sample struct. That should make the data passed from C to java a lot smaller, reducing JNI overhead.
        
        This might be more work than it's worth though. Can revisit once all of the runtime results are put up. I'll put up runtime on my single socket computer, and runtime on the double socket computer (also, do we ever expect servers with mutiple sockets? because if we have 4 or 8 sockets, the readings are going to be even bigger, which could be even more runtime!
        
        If we need a specific demonstration of how long it takes to bring different string sizes across the JNI, i can set up a JMH experiment for that, although that might be overkill.

\input{appendix}

\end{document}